---
title: "Models"
description: "Configure generative models for use in the Prompt, Code and Image nodes"
---

# Installing models

You can add to the available models by first [linking a supported service](/accounts) (OpenRouter, Groq or Gemini), then 
adding models as required on the [models page on the dashboard](https://runchat.app/dashboard/models).

After linking OpenRouter, you can install any of the models provided by their service. This includes many free and experimental models, as well as models from providers like OpenAI, Anthropic and DeepSeek.
Models typically trade off between speed, cost and features. 

# Using a model

The Prompt and Code nodes will use your default model unless you specify something else.
Use the dropdown on the node settings to select from an installed model and use this to make the prompt request. 
The Image node will only display models from Fal. The Prompt and Code node will display all installed language models. 